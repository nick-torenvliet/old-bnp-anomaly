{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnpy\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "FIG_SIZE = (14, 2)\n",
    "plt.rcParams['figure.figsize'] = FIG_SIZE\n",
    "\n",
    "# dataset_path = os.path.join('..', 'data')\n",
    "# all_data = bnpy.data.XData.read_csv(os.path.join(dataset_path, 'anomaly0245.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = 0\n",
    "data_init_size = 400000\n",
    "batch_size = 2000\n",
    "batchnum = int(data_init_size/batch_size)\n",
    "anomalies = [78, 98, 99, 104, 105, 106, 122, 124, 127, 128, 129, 130, 131, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166]\n",
    "cleans = [11, 12, 18, 19, 30, 33, 40, 52, 58, 59, 60, 61, 74, 79, 80, 81, 186, 187, 188, 189, 190, 191, 192, 193]\n",
    "\n",
    "all_data = pd.read_csv('/home/torenvln/git/bnp-anomaly/data/anomaly0245.csv')\n",
    "all_data.drop(all_data.columns[0], inplace=True, axis=1)\n",
    "\n",
    "init_data = all_data.head(data_init_size)\n",
    "init_data = bnpy.data.XData.from_dataframe(init_data)\n",
    "\n",
    "batches = []\n",
    "i = 0 \n",
    "while i < len(all_data)- batch_size:\n",
    "    batches.append(bnpy.data.XData.from_dataframe(all_data.iloc[i:i + batch_size]))\n",
    "    i += batch_size\n",
    "\n",
    "plt.plot(all_data)\n",
    "plt.plot(init_data.X, c='green')\n",
    "for i in anomalies:\n",
    "    plt.plot(list(range(i * batch_size, i * batch_size + batch_size)), batches[i].X, c='red')\n",
    "for i in cleans:\n",
    "    plt.plot(list(range(i * batch_size, i * batch_size + batch_size)), batches[i].X, c='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#\n",
    "# *DiagGauss* observation model\n",
    "# --------------------------------------------\n",
    "#\n",
    "\n",
    "gamma = 1.0\n",
    "sF = 1.0\n",
    "K = 10  # Initialize K component\n",
    "\n",
    "trained_model, info_dict = bnpy.run(\n",
    "    init_data, 'DPMixtureModel', 'DiagGauss', 'memoVB',\n",
    "    output_path=f'/tmp/faithful/trymoves-K={K}-gamma={gamma}-lik=DiagGauss-ECovMat={sF}*eye-moves=none/',\n",
    "    nLap=100, nTask=1, nBatch=batchnum, convergeThr=0.0001,\n",
    "    gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "    moves='birth,merge,delete,shuffle',\n",
    "    K=K, initname='randexamplesbydist', ts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Operations  \n",
    "\n",
    "- Only done on replacing the batchSS.\n",
    "- There are SS specific copy operations, find out and used them  \n",
    "- [] Figure out calculation of propXSS which is needed for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the learned SS from model and info dict\n",
    "S_k0 = copy.deepcopy(info_dict[\"SS\"])  # This is the S_k0, sufficient statistics of the component of entire dataset\n",
    "SSmemory = copy.deepcopy(info_dict[\"SSmemory\"])  # Dictionary of SS for all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(trained_model.obsModel.Post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LPanomaly = []\n",
    "SSanomaly = []\n",
    "for batch in batches:\n",
    "    LP = trained_model.calc_local_params(batch)\n",
    "    LPanomaly.append(LP)  # Calculation of responsibility, needed for next step\n",
    "    SSanomaly.append(trained_model.get_global_suff_stats(batch, LP))  # Calculation of SS for new data\n",
    "\n",
    "N = []\n",
    "K = []\n",
    "x = []\n",
    "xx = []\n",
    "beta = []\n",
    "for key in SSanomaly:\n",
    "    N.append(key.N)\n",
    "    K.append(key.K)\n",
    "    x.append(key.x)\n",
    "    xx.append(key.xx)\n",
    "x = np.vstack(x)\n",
    "xx = np.vstack(xx) \n",
    "K = np.sum(x > 1)\n",
    "\n",
    "\n",
    "index = list(range(0, len(x)))\n",
    "index = [el * batch_size for el in index]\n",
    "plt.plot(index, x, c='green')\n",
    "plt.show()\n",
    "plt.plot(index, xx, c='red')\n",
    "plt.show()\n",
    "plt.plot(all_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
