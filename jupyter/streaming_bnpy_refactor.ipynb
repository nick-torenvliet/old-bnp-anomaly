{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the required python libraries imported\n",
    "import bnpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook, push_notebook\n",
    "from bokeh.core.validation import silence\n",
    "from bokeh.core.validation.warnings import MISSING_RENDERERS\n",
    "from bokeh.layouts import column\n",
    "from IPython.core.display import display, HTML\n",
    "import bokeh\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicates to jupyer how the plots are to be displayed and sized and some other\n",
    "# housekeeping particular to this notebook\n",
    "display(HTML(\"<style>div.output_scroll { height: 600em; }</style>\"))\n",
    "silence(MISSING_RENDERERS, True)\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "\n",
    "# Theses values need to make sense, mod(data_init_size, batch_size) == 0\n",
    "data_start = 0\n",
    "data_init_size = 20000\n",
    "batch_size = 2000\n",
    "batchnum = int(data_init_size/batch_size)\n",
    "\n",
    "# all_data contains all the data\n",
    "all_data = pd.read_csv('../data/anomaly0245.csv')\n",
    "all_data.drop(all_data.columns[0], inplace=True, axis=1)\n",
    "\n",
    "# init_data contains the initialization data\n",
    "init_data = all_data.head(data_init_size)\n",
    "init_data = bnpy.data.XData.from_dataframe(init_data)\n",
    "\n",
    "data_set = bnpy.data.XData.from_dataframe(all_data)\n",
    "\n",
    "batches = []\n",
    "\n",
    "i = 0\n",
    "while i < len(all_data)- batch_size:\n",
    "    df = all_data.iloc[i:i + batch_size]\n",
    "    batches.append(bnpy.data.XData.from_dataframe(df))\n",
    "    i += batch_size\n",
    "\n",
    "# Graph the data for inspection if required\n",
    "# p = figure(title=\"Streaming Data\", x_axis_label='x', y_axis_label='y', plot_height=350, plot_width=1200)\n",
    "# add a line renderer with legend and line thickness\n",
    "# p.line(all_data.index.tolist(), all_data['anomaly'].tolist(), legend_label=\"Temp.\", line_width=2)\n",
    "# show the results\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the placekeeping and initilizing variables\n",
    "chain = 0\n",
    "x, eng_val, states, num_states = [], [], [], []\n",
    "step = 5000\n",
    "\n",
    "# Initialize bnpy model and do initial training\n",
    "# *DiagGauss* observation model\n",
    "gamma = 1.0\n",
    "sF = 1.0\n",
    "K = 25  # Initialize K component - this value places a max K the model can develop\n",
    "nLap = 10\n",
    "\n",
    "# cold start the model\n",
    "cold_start_model, cold_info_dict = bnpy.run(\n",
    "    init_data, 'DPMixtureModel', 'DiagGauss', 'memoVB',\n",
    "    output_path='/tmp/AsteriskK8/coldstart-K=10/',\n",
    "    nLap=nLap, nTask=1, nBatch=batchnum, convergeThr=0.0001,\n",
    "    gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "    K=K, initname='randexamplesbydist', ts=True, debug=False)\n",
    "\n",
    "# Initialize graphing vars for first pass with no data \n",
    "y = []\n",
    "x = []\n",
    "x_batches = []\n",
    "x_batch_post = []\n",
    "x_batch_pre = []\n",
    "K_model = []\n",
    "K_states = []\n",
    "index = []\n",
    "\n",
    "# Make this switch for first pass of warm start loop\n",
    "warm_start_model = cold_start_model\n",
    "warm_info_dict = cold_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(warm_start_model.obsModel.Post)\n",
    "# vars(warm_start_model.obsModel.Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "output_notebook()                \n",
    "p1 = figure(title=\"Dataset\", plot_height=200, plot_width=800)\n",
    "p2 = figure(title=\"Sufficient Statistics\", plot_height=100, plot_width=800)\n",
    "p3 = figure(title=\"Average K Resp\", plot_height=200, plot_width=800)\n",
    "#p4 = figure(title=\"K2\", plot_height=100, plot_width=800)\n",
    "#p5 = figure(title=\"K3\", plot_height=100, plot_width=800)\n",
    "p6 = figure(title=\"K\", plot_height=200, plot_width=800)\n",
    "p = column(p1, p2, p3, p6)# p3, p4, p5, p6)\n",
    "target = show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_idx = int(data_init_size/batch_size)\n",
    "ed_idx = int(data_init_size/batch_size) + 200\n",
    "elapsed = 0\n",
    "# for i in range(st_idx, len(batches)):\n",
    "for ii, abatch in enumerate(batches):\n",
    "    start = time.time()\n",
    "    LP = warm_start_model.calc_local_params(abatch)\n",
    "    #K_resp = [LP[\"resp\"][:,0], LP[\"resp\"][:,1], LP[\"resp\"][:,2]]\n",
    "    K_resp = np.mean(LP[\"resp\"], axis=0)\n",
    "    # Setup the bokeh plots and render via call back\n",
    "    line1 = p1.line(x = x, y = y, color='blue', name='g1', line_width=1)\n",
    "    line2 = p2.scatter(x = K * [index], y = x_batch_post, color='blue', name='g1', line_width=1)\n",
    "    line4 = p3.scatter(x = K * [index], y = K_resp , color='red', name='g4')\n",
    "    line7 = p6.scatter(x = index, y = LP['resp'].shape[1] , color='red', name='g4')\n",
    "    push_notebook(handle = target)\n",
    "\n",
    "    # Shift the dataset to include new incoming data   \n",
    "    start_idx = data_start + (ii*batch_size)\n",
    "    end_idx = data_start + ((ii+1)*batch_size)\n",
    "    new_dataset = data_set.make_subset(example_id_list = list(range(start_idx, end_idx)))\n",
    "\n",
    "    # Put together the warm start model - starting from the previous iteration \n",
    "    output_path = f'/tmp/AsteriskK8/warmstart-K=10/b{ii}'  # Dynamic output path according to batch\n",
    "    warm_start_model, warm_info_dict = bnpy.run(\n",
    "        new_dataset, 'DPMixtureModel', 'DiagGauss', 'memoVB',\n",
    "        output_path=output_path,\n",
    "        nLap=nLap, nTask=1, nBatch=batchnum, convergeThr=0.0001,\n",
    "        gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "        K=K, \n",
    "        initname=warm_info_dict['task_output_path'],\n",
    "        ts=True, debug=True)\n",
    "\n",
    "    # Check sufficient statistics on the new batch with the newly learned model \n",
    "    LPanomaly = []\n",
    "    SSanomaly = []\n",
    "    LP = warm_start_model.calc_local_params(abatch)\n",
    "    LPanomaly.append(LP)  # Calculation of responsibility, needed for next step\n",
    "    SSanomaly.append(warm_start_model.get_global_suff_stats(abatch, LP))  # Calculation of SS for new data\n",
    "    x_batch_post = []\n",
    "    xx_batch_post = []\n",
    "    K_model = []\n",
    "    K_states = []\n",
    "    for key in SSanomaly:\n",
    "        x_batch_post.append(key.x)\n",
    "        xx_batch_post.append(key.xx)    \n",
    "        K_model.append(key.K)\n",
    "    x_batch_post = np.vstack(x_batch_post)\n",
    "    xx_batch_post = np.vstack(xx_batch_post)\n",
    "    K_model = np.vstack(K_model)\n",
    "    \n",
    "    index = int(ii * batch_size) + batch_size\n",
    "    x_batch_pre = np.squeeze(np.squeeze(x_batch_pre))\n",
    "    x_batch_post = np.squeeze(np.squeeze(x_batch_post))\n",
    "    K_model = np.sum(x_batch_post > 1)\n",
    "    y = np.squeeze(abatch.X)\n",
    "    x = list(range(ii*len(abatch.X), ii*len(abatch.X) + len(abatch.X)))\n",
    "    end = time.time()\n",
    "    elapsed = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
