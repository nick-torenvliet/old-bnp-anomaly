{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the required python libraries imported\n",
    "import bnpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook, push_notebook\n",
    "from bokeh.core.validation import silence\n",
    "from bokeh.core.validation.warnings import MISSING_RENDERERS\n",
    "from bokeh.layouts import column\n",
    "from IPython.core.display import display, HTML\n",
    "import bokeh\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "# indicates to jupyer how the plots are to be displayed and sized and some other\n",
    "# housekeeping particular to this notebook\n",
    "display(HTML(\"<style>div.output_scroll { height: 600em; }</style>\"))\n",
    "silence(MISSING_RENDERERS, True)\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "\n",
    "data_start = 0\n",
    "data_init_size = 20000\n",
    "batch_size = 2000\n",
    "batchnum = int(data_init_size/batch_size)\n",
    "\n",
    "all_data = pd.read_csv('../data/anomaly0245.csv')\n",
    "all_data.drop(all_data.columns[0], inplace=True, axis=1)\n",
    "\n",
    "init_data = all_data.head(data_init_size)\n",
    "init_data = bnpy.data.XData.from_dataframe(init_data)\n",
    "\n",
    "data_set = bnpy.data.XData.from_dataframe(all_data)\n",
    "\n",
    "batches = []\n",
    "\n",
    "i = 0\n",
    "while i < len(all_data)- batch_size:\n",
    "    df = all_data.iloc[i:i + batch_size]\n",
    "    batches.append(bnpy.data.XData.from_dataframe(df))\n",
    "    i += batch_size\n",
    "\n",
    "# p = figure(title=\"Streaming Data\", x_axis_label='x', y_axis_label='y', plot_height=350, plot_width=1200)\n",
    "\n",
    "# add a line renderer with legend and line thickness\n",
    "# p.line(all_data.index.tolist(), all_data['anomaly'].tolist(), legend_label=\"Temp.\", line_width=2)\n",
    "\n",
    "# show the results\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the placekeeping and initilizing variables\n",
    "chain = 0\n",
    "x, eng_val, states, num_states = [], [], [], []\n",
    "#i = 300000\n",
    "step = 5000\n",
    "#print(i)\n",
    "\n",
    "# Initialize bnpy model and do initial training\n",
    "# *DiagGauss* observation model\n",
    "gamma = 1.0\n",
    "sF = 1.0\n",
    "K = 25  # Initialize K component\n",
    "nLap = 10\n",
    "\n",
    "cold_start_model, cold_info_dict = bnpy.run(\n",
    "    init_data, 'DPMixtureModel', 'DiagGauss', 'memoVB',\n",
    "    output_path='/tmp/AsteriskK8/coldstart-K=10/',\n",
    "    nLap=nLap, nTask=1, nBatch=batchnum, convergeThr=0.0001,\n",
    "    gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "    K=K, initname='randexamplesbydist', ts=True, debug=False)\n",
    "\n",
    "# Get the intial graphing data\n",
    "y = np.squeeze(init_data.X)\n",
    "x = list(range(0, len(init_data.X)))\n",
    "x_batches = []\n",
    "x_batch_post = []\n",
    "x_batch_pre = []\n",
    "K_model = []\n",
    "K_states = []\n",
    "index = []\n",
    "\n",
    "warm_start_model = cold_start_model\n",
    "warm_info_dict = cold_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(warm_start_model.obsModel.Post)\n",
    "# vars(warm_start_model.obsModel.Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "output_notebook()                \n",
    "p1 = figure(title=\"Dataset\", plot_height=100, plot_width=1200)\n",
    "p2 = figure(title=\"Sufficient Statistics\", plot_height=100, plot_width=1200)\n",
    "p3 = figure(title=\"K1\", plot_height=100, plot_width=1200)\n",
    "p4 = figure(title=\"K2\", plot_height=100, plot_width=1200)\n",
    "p5 = figure(title=\"K3\", plot_height=100, plot_width=1200)\n",
    "p6 = figure(title=\"K\", plot_height=100, plot_width=1200)\n",
    "p = column(p1, p2, p3, p4, p5, p6)\n",
    "target = show(p, notebook_handle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_idx = int(data_init_size/batch_size)\n",
    "ed_idx = int(data_init_size/batch_size) + 200\n",
    "elapsed = 0\n",
    "# for i in range(st_idx, len(batches)):\n",
    "for ii, abatch in enumerate(batches):\n",
    "    start = time.time()\n",
    "    LP = warm_start_model.calc_local_params(abatch)\n",
    "    K_resp = [LP[\"resp\"][:,0], LP[\"resp\"][:,1], LP[\"resp\"][:,2]]\n",
    "    # Setup the bokeh plots and render via call back\n",
    "    line1 = p1.line(x = x, y = y, color='blue', name='g1', line_width=1)\n",
    "    line2 = p2.scatter(x = index, y = x_batch_post , color='red', name='g2')\n",
    "    line4 = p3.scatter(x = index, y = K_resp[0] , color='red', name='g4')\n",
    "    line5 = p4.scatter(x = index, y = K_resp[1] , color='red', name='g4')\n",
    "    line6 = p5.scatter(x = index, y = K_resp[2] , color='red', name='g4')\n",
    "    line7 = p6.scatter(x = index, y = K_model , color='red', name='g4')\n",
    "    line8 = p6.scatter(x = index, y = elapsed , color='red', name='g4')\n",
    "    push_notebook(handle = target)\n",
    "    \n",
    "    # Shift the dataset to include new incoming data   \n",
    "#     new_dataset = data_set.make_subset(example_id_list = list(range(i * batch_size - data_init_size, i * batch_size)))\n",
    "    start_idx = data_start + (ii*batch_size)\n",
    "    end_idx = data_start + ((ii+1)*batch_size)\n",
    "    new_dataset = data_set.make_subset(example_id_list = list(range(start_idx, end_idx)))\n",
    "    \n",
    "    # Check sufficient statistics on the new batch with the previously learned model \n",
    "    LPanomaly = []\n",
    "    SSanomaly = []\n",
    "#     LP = warm_start_model.calc_local_params(batches[i])\n",
    "#     K_resp = [LP[\"resp\"][:,0], LP[\"resp\"][:,1], LP[\"resp\"][:,2]]\n",
    "    LPanomaly.append(LP)  # Calculation of responsibility, needed for next step\n",
    "    SSanomaly.append(warm_start_model.get_global_suff_stats(abatch, LP))  # Calculation of SS for new data\n",
    "    x_batch_pre = []\n",
    "    xx_batch_pre = []\n",
    "    for key in SSanomaly:\n",
    "        x_batch_pre.append(key.x)\n",
    "        xx_batch_pre.append(key.xx)\n",
    "    x_batch_pre = np.vstack(x_batch_pre)\n",
    "    xx_batch_pre = np.vstack(xx_batch_pre)\n",
    "    \n",
    "    ### CHANGES HERE\n",
    "    output_path = f'/tmp/AsteriskK8/warmstart-K=10/b{ii}'  # Dynamic output path according to batch\n",
    "    if ii == 0:  # First batch use the cold start.\n",
    "        warm_init_path = cold_info_dict['task_output_path']\n",
    "    else:  # After, use previous warm start.\n",
    "        warm_init_path = warm_info_dict['task_output_path']\n",
    "    warm_start_model, warm_info_dict = bnpy.run(\n",
    "        new_dataset, 'DPMixtureModel', 'DiagGauss', 'memoVB',\n",
    "        output_path=output_path,\n",
    "        nLap=nLap, nTask=1, nBatch=batchnum, convergeThr=0.0001,\n",
    "        gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "        K=K, initname=warm_init_path, ts=True, debug=True)#     trained_model, trained_dict = bnpy.run(\n",
    "    # Check sufficient statistics on the new batch with the newly learned model \n",
    "    LPanomaly = []\n",
    "    SSanomaly = []\n",
    "    LP = warm_start_model.calc_local_params(abatch)\n",
    "    LPanomaly.append(LP)  # Calculation of responsibility, needed for next step\n",
    "    SSanomaly.append(warm_start_model.get_global_suff_stats(abatch, LP))  # Calculation of SS for new data\n",
    "    x_batch_post = []\n",
    "    xx_batch_post = []\n",
    "    K_model = []\n",
    "    K_states = []\n",
    "    for key in SSanomaly:\n",
    "        x_batch_post.append(key.x)\n",
    "        xx_batch_post.append(key.xx)    \n",
    "        K_model.append(key.K)\n",
    "    x_batch_post = np.vstack(x_batch_post)\n",
    "    xx_batch_post = np.vstack(xx_batch_post)\n",
    "    K_model = np.vstack(K_model)\n",
    "    \n",
    "    index = int(ii * batch_size)\n",
    "    x_batch_pre = np.squeeze(np.squeeze(x_batch_pre))\n",
    "    x_batch_post = np.squeeze(np.squeeze(x_batch_post))\n",
    "    K_model = np.sum(x_batch_post > 1)\n",
    "    y = np.squeeze(abatch.X)\n",
    "    x = list(range(ii*len(abatch.X), ii*len(abatch.X) + len(abatch.X)))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
